# Juran Zhang, 912664699# ECI289I Homwork2 ex1# Compare hill climbing and grid searchfrom __future__ import divisionimport numpy as np import matplotlib.pyplot as plt# Peaks function definitiondef peaks(x):	a = 3*(1-x[0])**2*np.exp(-(x[0]**2) - (x[1]+1)**2)	b = 10*(x[0]/5 - x[0]**3 - x[1]**5)*np.exp(-x[0]**2-x[1]**2)	c = (1/3)*np.exp(-(x[0]+1)**2 - x[1]**2)	return a - b - c + 6.551ub = 3.0lb = -3.0d = 2 # dimension of decision variable spaces = 0.1 # stdev of normal noise (if this is too big, it's just random search!)num_seeds = 5max_NFE = 50000ft1 = np.zeros((num_seeds, max_NFE))ft2 = np.zeros((num_seeds, max_NFE))ft3 = np.zeros((num_seeds, max_NFE))xt = np.zeros((2, max_NFE))p1 = 0.01p2 = 0.5p3 = 0.99# hill climbingfor seed in range(num_seeds):    np.random.seed(seed)  	# random initial starting point    x_current = np.random.uniform(lb, ub, d)    f_current = peaks(x_current)    x_best,f_best = x_current,f_current    for i in range(max_NFE):        r = np.random.rand()        if r < p1:            x_trial = x_current + np.random.normal(0,s,d)            while np.any((x_trial > ub) | (x_trial < lb)):                x_trial = x_current + np.random.normal(0,s,d)        else:            x_trial = np.random.uniform(lb,ub,d)        f_trial = peaks(x_trial)        if f_trial < f_current:            x_current = x_trial            f_current = f_trial        if f_trial < f_best:            x_best = x_trial            f_best = f_trial        ft1[seed,i] = f_current        xt[:,i] = x_current    # for each trial print the result (but the traces are saved in ft)    print x_best    print f_best# hill climbingfor seed in range(num_seeds):    np.random.seed(seed)    # random initial starting point    x_current = np.random.uniform(lb, ub, d)    f_current = peaks(x_current)    x_best,f_best = x_current,f_current    for i in range(max_NFE):        r = np.random.rand()        if r < p2:            x_trial = x_current + np.random.normal(0,s,d)            while np.any((x_trial > ub) | (x_trial < lb)):                x_trial = x_current + np.random.normal(0,s,d)        else:            x_trial = np.random.uniform(lb,ub,d)        f_trial = peaks(x_trial)        if f_trial < f_current:            x_current = x_trial            f_current = f_trial        if f_trial < f_best:            x_best = x_trial            f_best = f_trial        ft2[seed,i] = f_current        xt[:,i] = x_current    # for each trial print the result (but the traces are saved in ft)    print x_best    print f_best# hill climbingfor seed in range(num_seeds):    np.random.seed(seed)    # random initial starting point    x_current = np.random.uniform(lb, ub, d)    f_current = peaks(x_current)    x_best,f_best = x_current,f_current    for i in range(max_NFE):        r = np.random.rand()        if r < p3:            x_trial = x_current + np.random.normal(0,s,d)            while np.any((x_trial > ub) | (x_trial < lb)):                x_trial = x_current + np.random.normal(0,s,d)        else:            x_trial = np.random.uniform(lb,ub,d)        f_trial = peaks(x_trial)        if f_trial < f_current:            x_current = x_trial            f_current = f_trial        if f_trial < f_best:            x_best = x_trial            f_best = f_trial        ft3[seed,i] = f_current        xt[:,i] = x_current    # for each trial print the result (but the traces are saved in ft)    print x_best    print f_best# grid search# add a line for "enumeration"enumy = np.arange(2.0,-3.0,-1.0)enumx = (10**(-enumy)*(ub-lb))**dplt.subplot(1,3,1)plt.loglog(ft1.T, color='steelblue', linewidth=1)plt.loglog(enumx,10**enumy, color='indianred', linewidth=2)plt.xlabel('Iterations, p = 0.01')plt.ylabel('Objective Value')plt.subplot(1,3,2)plt.loglog(ft2.T, color='steelblue', linewidth=1)plt.loglog(enumx,10**enumy, color='indianred', linewidth=2)plt.xlabel('Iterations, p = 0.5')plt.ylabel('Objective Value')plt.subplot(1,3,3)plt.loglog(ft3.T, color='steelblue', linewidth=1)plt.loglog(enumx,10**enumy, color='indianred', linewidth=2)plt.xlabel('Iterations, p = 0.99')plt.ylabel('Objective Value')plt.show()